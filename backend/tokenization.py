# Tokenization
# Tokenize a given raw text for later use, either for indexing or ranking


# Tokenize a given text into singular Tokens and the total number of their occurences
# @param text : String
# Return set(String -> Int)
def tokenize(text):
    #TODO:
    pass