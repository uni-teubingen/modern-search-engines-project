# 1. Web Crawling & Indexing
#Crawl the web to discover **English content related to TÃ¼bingen**. The crawled content should be stored locally. 
#If interrupted, your crawler should be able to re-start and pick up the crawling process at any time.

#Crawl the web. You need (at least) two parameters:
	#frontier: The frontier of known URLs to crawl. You will initially populate this with your seed set of URLs and later maintain all discovered (but not yet crawled) URLs here.
	#index: The location of the local index storing the discovered documents. 
def crawl(frontier, index):
    #TODO: Implement me
	pass